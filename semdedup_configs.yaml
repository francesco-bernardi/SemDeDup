# -- model
model_name: "openai/clip-vit-base-patch32"
# -- directories
save_folder: "data/"
tar_files_directory: "data/raw"
sorted_clusters_path: "data/sorted_clusters"
semdedup_pruning_tables_path: "data/dataframes"
embs_memory_loc: "data/embeddings/embs.npy"
path_memory_loc: "data/embeddings/path.npy"
# -- data type
paths_str_type: 'U256'
embed_float_type: 'float32'
# -- data loader
num_workers: 0
# -- dataset size
dataset_size: 20220
batch_size: 16
# -- embeddings size
emd_size: 512
# -- Clustering parameters
clustering:
  num_clusters: 50 #50000
  niter: 100
  keep_hard: True # True for hard examples
  sim_metric: 'cosine' # choose form ['cosine', 'l2']
  Kmeans_with_cos_dist: True # True for using cosine similarity for kmeans clustering
  save_folder: "data/clustering"
  text_emb_memory_loc: None
# -- seed
seed: 1234
# -- largest cluster size the memory is large enough to process. If the cluster size is larger than it, we will devide the cluster into small clusters and process each one separately.
largest_cluster_size_to_process: 10000000
eps: 0.1
eps_list: [
      0.00001, 0.00002, 0.00005, 0.0001, 0.0002, 0.0005, 0.001, 
      0.002, 0.005, 0.01, 0.02, 0.03, 0.04, 0.05, 
      0.06, 0.07, 0.08, 0.09, 0.1, 0.11, 0.12, 
      0.13, 0.14, 0.15, 0.16, 0.17, 0.18, 0.19,
      0.2, 0.21, 0.22, 0.23, 0.24, 0.25, 0.26, 
      0.27, 0.28, 0.29, 0.3, 0.32, 0.34, 0.36, 
      0.38, 0.4, 0.42, 0.44, 0.46, 0.48, 0.5,
      0.55, 0.6, 0.65, 0.7, 0.75, 0.8, 0.85,
      0.9, 0.95, 1.0, 1.1, 1.2, 1.3, 1.4, 
      1.5, 1.6, 1.7, 1.8, 1.9, 2.0, 2.2, 2.4,
      2.6, 2.8, 3.0, 3.2, 3.4, 3.6, 3.8, 
      4.0, 4.2, 4.4, 4.6, 4.8, 5.0
      ]
which_to_keep: "easy"
# -- output
output_txt_path: "data/kept_examples.txt"